
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://wzbxpy.github.io/LLM-System-and-Engineering/paper_list/">
      
      
        <link rel="prev" href="..">
      
      
        <link rel="next" href="../Project%20Graph%20learning/">
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.22">
    
    
      
        <title>论文列表 - LLM System and Engineering</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.84d31ad4.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../style.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#_1" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="LLM System and Engineering" class="md-header__button md-logo" aria-label="LLM System and Engineering" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            LLM System and Engineering
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              论文列表
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="LLM System and Engineering" class="md-nav__button md-logo" aria-label="LLM System and Engineering" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    LLM System and Engineering
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    大模型系统与工程
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    论文列表
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    论文列表
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    <span class="md-ellipsis">
      模型架构（李世鹏）
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    <span class="md-ellipsis">
      推理服务和请求调度（李世鹏）
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    <span class="md-ellipsis">
      分布式训练、推理（周宇航）
    </span>
  </a>
  
    <nav class="md-nav" aria-label="分布式训练、推理（周宇航）">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    <span class="md-ellipsis">
      分布式训练方向
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_6" class="md-nav__link">
    <span class="md-ellipsis">
      分布式推理方向
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_7" class="md-nav__link">
    <span class="md-ellipsis">
      向量数据库方向（陈力峥，赵可泰）
    </span>
  </a>
  
    <nav class="md-nav" aria-label="向量数据库方向（陈力峥，赵可泰）">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#anns" class="md-nav__link">
    <span class="md-ellipsis">
      ANNS 算法
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ANNS 算法">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#graph-based-anns" class="md-nav__link">
    <span class="md-ellipsis">
      Graph-based ANNS
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#quantization-based-anns" class="md-nav__link">
    <span class="md-ellipsis">
      Quantization-based ANNS
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tree-based-anns" class="md-nav__link">
    <span class="md-ellipsis">
      Tree-based ANNS
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hash-based-anns" class="md-nav__link">
    <span class="md-ellipsis">
      Hash-based ANNS
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#anns_1" class="md-nav__link">
    <span class="md-ellipsis">
      ANNS 混合检索
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#anns_2" class="md-nav__link">
    <span class="md-ellipsis">
      流式 ANNS
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_8" class="md-nav__link">
    <span class="md-ellipsis">
      大模型内存管理
    </span>
  </a>
  
    <nav class="md-nav" aria-label="大模型内存管理">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#kv-cache" class="md-nav__link">
    <span class="md-ellipsis">
      kv cache管理
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_9" class="md-nav__link">
    <span class="md-ellipsis">
      训练内存卸载
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_10" class="md-nav__link">
    <span class="md-ellipsis">
      卸载推理系统
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#overlap" class="md-nav__link">
    <span class="md-ellipsis">
      计算通信 Overlap 优化
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_11" class="md-nav__link">
    <span class="md-ellipsis">
      强化学习
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#for" class="md-nav__link">
    <span class="md-ellipsis">
      大模型 for 通信（彭于波）
    </span>
  </a>
  
    <nav class="md-nav" aria-label="大模型 for 通信（彭于波）">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_12" class="md-nav__link">
    <span class="md-ellipsis">
      语义通信方向
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_13" class="md-nav__link">
    <span class="md-ellipsis">
      多模态通感一体化方向
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_14" class="md-nav__link">
    <span class="md-ellipsis">
      投机解码（李世鹏）
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_15" class="md-nav__link">
    <span class="md-ellipsis">
      压缩和量化（李世鹏）
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_16" class="md-nav__link">
    <span class="md-ellipsis">
      大模型训练加速（崔正奇）
    </span>
  </a>
  
    <nav class="md-nav" aria-label="大模型训练加速（崔正奇）">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_17" class="md-nav__link">
    <span class="md-ellipsis">
      在网计算相关
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_18" class="md-nav__link">
    <span class="md-ellipsis">
      分布式训练
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_19" class="md-nav__link">
    <span class="md-ellipsis">
      拥塞控制
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ebpf" class="md-nav__link">
    <span class="md-ellipsis">
      网络协议栈优化与eBPF（章振辉）
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tcp" class="md-nav__link">
    <span class="md-ellipsis">
      高性能TCP协议栈
    </span>
  </a>
  
    <nav class="md-nav" aria-label="高性能TCP协议栈">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ebpf_1" class="md-nav__link">
    <span class="md-ellipsis">
      eBPF
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#related-papers-in-sosp25" class="md-nav__link">
    <span class="md-ellipsis">
      Related Papers in SOSP25
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Related Papers in SOSP25">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#llm-training" class="md-nav__link">
    <span class="md-ellipsis">
      LLM Training
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llm-inference" class="md-nav__link">
    <span class="md-ellipsis">
      LLM Inference
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Project Graph learning
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Project Graph learning
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Project%20Graph%20learning/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Graph Learning and Analysis
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Project Speculative Decoding
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Project Speculative Decoding
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Project%20Speculative%20Decoding/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    大模型推理优化-投机解码性能优化
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Project from 周宇航
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            Project from 周宇航
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Project%20from%20%E5%91%A8%E5%AE%87%E8%88%AA/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    大模型训练与推理性能优化
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Project from 崔正奇
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            Project from 崔正奇
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Project%20from%20%E5%B4%94%E6%AD%A3%E5%A5%87/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Accelerating Collective Communication with Better Congestion Control from 崔正奇
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7" >
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Project from 彭于波
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            Project from 彭于波
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Project%20from%20%E5%BD%AD%E4%BA%8E%E6%B3%A2/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    研究方向
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8" >
        
          
          <label class="md-nav__link" for="__nav_8" id="__nav_8_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Project from 王梓博
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_8">
            <span class="md-nav__icon md-icon"></span>
            Project from 王梓博
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Project%20from%20%E7%8E%8B%E6%A2%93%E5%8D%9A/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    基于内存池优化的LLM推理系统
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_9" >
        
          
          <label class="md-nav__link" for="__nav_9" id="__nav_9_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Project ANNS and LLM
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_9">
            <span class="md-nav__icon md-icon"></span>
            Project ANNS and LLM
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Project-ANNS-and-LLM/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    近似最近邻搜索（ANNS）
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_10" >
        
          
          <label class="md-nav__link" for="__nav_10" id="__nav_10_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Project Security and Privacy in Real world LLM Based Systems
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_10_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_10">
            <span class="md-nav__icon md-icon"></span>
            Project Security and Privacy in Real world LLM Based Systems
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Project-Security%20and%20Privacy%20in%20Real-world%20LLM-Based%20Systems/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    课程介绍：基于大型语言模型的现实世界系统中的安全（项目式）
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_11" >
        
          
          <label class="md-nav__link" for="__nav_11" id="__nav_11_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Homework1
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_11_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_11">
            <span class="md-nav__icon md-icon"></span>
            Homework1
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../homework1/paperlist/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Paperlist
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../homework1/readme/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Assignment 1: 论文审稿
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    <span class="md-ellipsis">
      模型架构（李世鹏）
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    <span class="md-ellipsis">
      推理服务和请求调度（李世鹏）
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    <span class="md-ellipsis">
      分布式训练、推理（周宇航）
    </span>
  </a>
  
    <nav class="md-nav" aria-label="分布式训练、推理（周宇航）">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    <span class="md-ellipsis">
      分布式训练方向
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_6" class="md-nav__link">
    <span class="md-ellipsis">
      分布式推理方向
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_7" class="md-nav__link">
    <span class="md-ellipsis">
      向量数据库方向（陈力峥，赵可泰）
    </span>
  </a>
  
    <nav class="md-nav" aria-label="向量数据库方向（陈力峥，赵可泰）">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#anns" class="md-nav__link">
    <span class="md-ellipsis">
      ANNS 算法
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ANNS 算法">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#graph-based-anns" class="md-nav__link">
    <span class="md-ellipsis">
      Graph-based ANNS
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#quantization-based-anns" class="md-nav__link">
    <span class="md-ellipsis">
      Quantization-based ANNS
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tree-based-anns" class="md-nav__link">
    <span class="md-ellipsis">
      Tree-based ANNS
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hash-based-anns" class="md-nav__link">
    <span class="md-ellipsis">
      Hash-based ANNS
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#anns_1" class="md-nav__link">
    <span class="md-ellipsis">
      ANNS 混合检索
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#anns_2" class="md-nav__link">
    <span class="md-ellipsis">
      流式 ANNS
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_8" class="md-nav__link">
    <span class="md-ellipsis">
      大模型内存管理
    </span>
  </a>
  
    <nav class="md-nav" aria-label="大模型内存管理">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#kv-cache" class="md-nav__link">
    <span class="md-ellipsis">
      kv cache管理
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_9" class="md-nav__link">
    <span class="md-ellipsis">
      训练内存卸载
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_10" class="md-nav__link">
    <span class="md-ellipsis">
      卸载推理系统
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#overlap" class="md-nav__link">
    <span class="md-ellipsis">
      计算通信 Overlap 优化
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_11" class="md-nav__link">
    <span class="md-ellipsis">
      强化学习
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#for" class="md-nav__link">
    <span class="md-ellipsis">
      大模型 for 通信（彭于波）
    </span>
  </a>
  
    <nav class="md-nav" aria-label="大模型 for 通信（彭于波）">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_12" class="md-nav__link">
    <span class="md-ellipsis">
      语义通信方向
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_13" class="md-nav__link">
    <span class="md-ellipsis">
      多模态通感一体化方向
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_14" class="md-nav__link">
    <span class="md-ellipsis">
      投机解码（李世鹏）
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_15" class="md-nav__link">
    <span class="md-ellipsis">
      压缩和量化（李世鹏）
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_16" class="md-nav__link">
    <span class="md-ellipsis">
      大模型训练加速（崔正奇）
    </span>
  </a>
  
    <nav class="md-nav" aria-label="大模型训练加速（崔正奇）">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_17" class="md-nav__link">
    <span class="md-ellipsis">
      在网计算相关
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_18" class="md-nav__link">
    <span class="md-ellipsis">
      分布式训练
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_19" class="md-nav__link">
    <span class="md-ellipsis">
      拥塞控制
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ebpf" class="md-nav__link">
    <span class="md-ellipsis">
      网络协议栈优化与eBPF（章振辉）
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tcp" class="md-nav__link">
    <span class="md-ellipsis">
      高性能TCP协议栈
    </span>
  </a>
  
    <nav class="md-nav" aria-label="高性能TCP协议栈">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ebpf_1" class="md-nav__link">
    <span class="md-ellipsis">
      eBPF
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#related-papers-in-sosp25" class="md-nav__link">
    <span class="md-ellipsis">
      Related Papers in SOSP25
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Related Papers in SOSP25">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#llm-training" class="md-nav__link">
    <span class="md-ellipsis">
      LLM Training
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llm-inference" class="md-nav__link">
    <span class="md-ellipsis">
      LLM Inference
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="_1">论文列表</h1>
<h2 id="_2">模型架构（李世鹏）</h2>
<ol>
<li>
<p><strong>Attention Is All You Need</strong> (2017)</p>
<ul>
<li><strong>作者</strong>: Vaswani et al. (Google)</li>
<li><strong>核心贡献</strong>: 提出了<strong>Transformer</strong>架构，完全基于自注意力（Self-Attention）机制，摒弃了传统的循环（RNN）和卷积（CNN）结构。这是迄今为止大模型领域最基础、最核心的论文，为后续所有LLM奠定了架构基础，是无可争议的奠基之作，引用量超过10万次。</li>
</ul>
</li>
<li>
<p><strong>LLaMA: Open and Efficient Foundation Language Models</strong> (2023)</p>
<ul>
<li><strong>作者</strong>: Hugo Touvron et al. (Meta AI)</li>
<li><strong>核心贡献</strong>: 对Transformer进行了一系列<strong>精妙的优化设计</strong>。包括使用<strong>RMSNorm</strong>、<strong>SwiGLU</strong>激活函数、<strong>RoPE</strong>位置编码等。证明了通过更好的数据、干净的架构和高效的训练，参数量更小的模型可以超越更大规模的模型，引发了"小而精"模型和开源LLM的浪潮，是许多后续模型的基石。</li>
</ul>
</li>
<li>
<p><strong>RetNet: Retentive Network: A Successor to Transformer for Large Language Models</strong> (2023)</p>
<ul>
<li><strong>作者</strong>: Microsoft Research</li>
<li><strong>核心贡献</strong>: 提出了一种名为<strong>Retention（保留）</strong>机制的新架构，旨在同时实现<strong>训练并行化、低成本推理和良好的性能</strong>，解决Transformer在推理时计算成本高的问题。</li>
</ul>
</li>
<li>
<p><strong>Mixture of Experts (MoE)</strong></p>
<ul>
<li><strong>代表论文</strong>: <strong>GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding</strong> (2020) &amp; <strong>Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity</strong> (2021)</li>
<li><strong>作者</strong>: Google Research</li>
<li><strong>核心贡献</strong>: 将<strong>混合专家（MoE）</strong>系统成功引入到Transformer架构中。通过让每个输入只激活一部分网络（"专家"），实现了模型参数量巨幅增长（如万亿参数）而计算成本基本不变，解决了纯稠密模型scaling的瓶颈，是目前超大规模模型（如DeepSeek-R1）的核心技术，是scaling law下的关键架构创新。</li>
</ul>
</li>
<li>
<p><strong>RWKV: Reinventing RNNs for the Transformer Era</strong> (2022-ongoing)</p>
<ul>
<li><strong>作者</strong>: Bo Peng et al.</li>
<li><strong>核心贡献</strong>: 提出了一种新颖的架构，<strong>将Transformer的高效并行训练与RNN的低成本线性推理相结合</strong>。它不再是传统的Transformer，而是一种"RNN Transformer"，推理时不需要K-V Cache，内存占用极低，且支持无限上下文；在开源社区非常热门，被认为是挑战Transformer统治地位的有力候选之一，特别适合资源受限的场景。</li>
</ul>
</li>
<li>
<p><strong>Mamba: Linear-Time Sequence Modeling with Selective State Spaces</strong> (2023)</p>
<ul>
<li><strong>作者</strong>: Albert Gu &amp; Tri Dao (CMU, Stanford)</li>
<li><strong>核心贡献</strong>: 基于<strong>结构化状态空间模型（SSM）</strong>，提出了<strong>Mamba</strong>架构。它引入了"选择性"机制，使模型能够根据输入内容动态地选择性地传递或遗忘信息，在长序列建模上性能显著超越Transformer，且具有线性时间的推理效率，引发了SSM相关研究的热潮。</li>
</ul>
</li>
<li>
<p><strong>The Gemini 1.5 Technical Report</strong> (2024)</p>
<ul>
<li><strong>作者</strong>: Google DeepMind</li>
<li><strong>核心贡献</strong>: 其架构核心是<strong>MoE Transformer</strong>，但最大的热点在于其引入了<strong>全新的高效注意力机制</strong>（可能是MLA，Multi-Head Latent Attention），从而实现了<strong>百万级别的超长上下文（Context Window）</strong>支持，并且性能衰减极小；重新定义了上下文长度的可能性，其背后的高效架构设计是当前的研究前沿和热点。</li>
</ul>
</li>
<li>
<p><strong>Griffin: Mixing Gated Linear Recurrences with Local Attention for Efficient Language Models</strong> (2024)</p>
<ul>
<li><strong>作者</strong>: Google DeepMind</li>
<li><strong>核心贡献</strong>: 提出了一种<strong>将线性递归（RNN）与局部注意力（Local Attention）相结合</strong>的新架构。它在保持高效并行训练的同时，实现了媲美Transformer的性能，并且推理速度更快、内存效率更高，展示了混合架构的强大潜力。</li>
</ul>
</li>
<li>
<p><strong>Vision Transformer (ViT)</strong> (2020)</p>
<ul>
<li><strong>作者</strong>: Dosovitskiy et al. (Google)</li>
<li><strong>核心贡献</strong>: 证明了<strong>纯Transformer架构在计算机视觉任务上同样可以取得state-of-the-art的性能</strong>。它将图像切分为Patch序列，然后直接作为输入送入标准Transformer Encoder。这项工作打破了CV和NLP的架构壁垒，开启了多模态模型的基础；开创了视觉任务的新范式，是ViT、DeiT、Swin Transformer等无数工作的起点。</li>
</ul>
</li>
<li>
<p><strong>BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</strong> (2018)</p>
<ul>
<li><strong>作者</strong>: Devlin et al. (Google)</li>
<li><strong>核心贡献</strong>: 虽然基于Transformer Encoder，但其架构设计上的热点在于<strong>掩码语言模型（MLM）预训练目标</strong>和<strong>双向上下文编码</strong>。这种预训练架构设计使得模型能生成深度的上下文词表征，在NLP任务上取得了颠覆性的效果；与GPT（Decoder-only）并驾齐驱，开创了NLP的预训练时代，其架构思想影响深远。</li>
</ul>
</li>
</ol>
<h2 id="_3">推理服务和请求调度（李世鹏）</h2>
<ul>
<li>
<p><strong>Infinite-LLM: Efficient LLM Service for Long Context with DistAttention and Distributed KVCache</strong></p>
</li>
<li>
<p><strong>Hydragen: High-Throughput LLM Inference with Shared Prefixes</strong></p>
</li>
<li>
<p><strong>ZipCache: Accurate and Efficient KV Cache Quantization with Salient Token Identification</strong></p>
</li>
<li>
<p><strong>Optimizing Large Language Model Serving with Layer-wise KV Cache Management</strong></p>
</li>
<li>
<p><strong>Cache-Craft: Managing Chunk-Caches for Efficient Retrieval-Augmented Generation</strong></p>
</li>
<li>
<p><strong>DeepSpeed-FastGen: High-throughput Text Generation for LLMs via MII and DeepSpeed-Inference</strong></p>
</li>
<li>
<p><strong>BatchLLM: Optimizing Large Batched LLM Inference with Global Prefix Sharing and Throughput-oriented Token Batching</strong></p>
</li>
<li>
<p><strong>Efficient LLM Scheduling by Learning to Rank</strong></p>
</li>
<li>
<p><strong>Towards SLO-Optimized LLM Serving via Automatic Inference Engine Tuning</strong></p>
</li>
<li>
<p><strong>vTensor: Flexible Virtual Tensor Management for Efficient LLM Serving</strong></p>
</li>
<li>
<p><strong>vAttention: Dynamic Memory Management for Serving LLMs without PagedAttention</strong></p>
</li>
<li>
<p><strong>Accelerating LLM Inference Throughput via Asynchronous KV Cache Prefetching</strong></p>
</li>
</ul>
<h2 id="_4">分布式训练、推理（周宇航）</h2>
<h3 id="_5">分布式训练方向</h3>
<ul>
<li>
<p><strong>Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism (2019)</strong>  </p>
</li>
<li>
<p><strong>Megatron-LM: Reducing Activation Recomputation in Large Transformer Models (2021)</strong></p>
</li>
<li>
<p><strong>ZeRO: Memory Optimizations Toward Training Trillion Parameter Models (2020)</strong>  </p>
</li>
<li>
<p><strong>Alpa: Automating Inter- and Intra-Operator Parallelism for Distributed Deep Learning (2022)</strong>  </p>
</li>
<li>
<p><strong>FSDP: Fully Sharded Data Parallel (2023)</strong>  </p>
</li>
<li>
<p><strong>MegaScale: Scaling Large Language Model Training to More Than 10,000 GPUs (2024)</strong></p>
</li>
<li>
<p><strong>Minder: Faulty Machine Detection for Large-scale Distributed Model Training (2025)</strong></p>
</li>
<li>
<p><strong>Towards LLM-Based Failure Localization in Production-Scale Networks (2025)</strong></p>
</li>
<li>
<p><strong>Recycle: Resilient Training of Large DNNs using Pipeline Adaptation (2024)</strong></p>
</li>
</ul>
<hr />
<h3 id="_6">分布式推理方向</h3>
<ul>
<li>
<p><strong>FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness (2022)</strong>  </p>
</li>
<li>
<p><strong>FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning (2023)</strong>  </p>
</li>
<li>
<p><strong>Orca: A Distributed Serving System for Transformer-Based Generative Models (2023)</strong>  </p>
</li>
<li>
<p><strong>Efficient Memory Management for Large Language Model Serving with PagedAttention (2023)</strong>  </p>
</li>
<li>
<p><strong>Accelerating Large Language Model Decoding with Speculative Sampling (2023)</strong></p>
</li>
<li>
<p><strong>Taming Throughput-Latency Tradeoff in LLM Inference with Sarathi-Serve (2024)</strong>  </p>
</li>
<li>
<p><strong>DistServe: Disaggregating Prefill and Decoding for LLM Serving (2024)</strong>  </p>
</li>
<li>
<p><strong>Native Sparse Attention: Hardware-Aligned and Natively Trainable Sparse Attention (2025)</strong></p>
</li>
<li>
<p><strong>MegaScale-Infer: Serving Mixture-of-Experts at Scale with Disaggregated Expert Parallelism (2025)</strong>  </p>
</li>
<li>
<p><strong>LLMCompass: Enabling Efficient Hardware Design for Large Language Model Inference (2024)</strong></p>
</li>
<li>
<p><strong>AMALI: An Analytical Model for Accurately Modeling LLM Inference on Modern GPUs (2025)</strong></p>
</li>
</ul>
<hr />
<h2 id="_7">向量数据库方向（陈力峥，赵可泰）</h2>
<h3 id="anns">ANNS 算法</h3>
<h4 id="graph-based-anns">Graph-based ANNS</h4>
<ul>
<li>
<p><strong>Approximate nearest neighbor algorithm based on navigable small world graphs (2014)</strong></p>
</li>
<li>
<p><strong>Efficient and Robust Approximate Nearest Neighbor Search Using Hierarchical Navigable Small World Graphs (2018)</strong>  </p>
</li>
<li>
<p><strong>DiskANN: Fast Accurate Billion-Point Nearest Neighbor Search on a Single Node (2019)</strong>  </p>
</li>
<li>
<p><strong>A Comprehensive Survey and Experimental Comparison of Graph-Based Approximate Nearest Neighbor Search (2021)</strong> </p>
</li>
</ul>
<h4 id="quantization-based-anns">Quantization-based ANNS</h4>
<ul>
<li>
<p><strong>Product quantization for nearest neighbor search (2010)</strong></p>
</li>
<li>
<p><strong>Knowledge Distillation for High Dimensional Search Index (2024)</strong></p>
</li>
</ul>
<h4 id="tree-based-anns">Tree-based ANNS</h4>
<ul>
<li>
<p><strong>Scalable Nearest Neighbor Algorithms for High Dimensional Data (2020)</strong></p>
</li>
<li>
<p><strong>Adaptive Indexing in High-Dimensional Metric Spaces (2023)</strong></p>
</li>
</ul>
<h4 id="hash-based-anns">Hash-based ANNS</h4>
<ul>
<li>
<p><strong>Near-Optimal Hashing Algorithms for Approximate Nearest Neighbor in High Dimensions (2008)</strong></p>
</li>
<li>
<p><strong>DB-LSH: Locality-Sensitive Hashing with Query-based Dynamic Bucketing (2023)</strong></p>
</li>
</ul>
<h3 id="anns_1">ANNS 混合检索</h3>
<ul>
<li>
<p><strong>AnalyticDB-V: A Hybrid Analytical Engine Towards Query Fusion for Structured and Unstructured Data (2020)</strong>  </p>
</li>
<li>
<p><strong>Navigable Proximity Graph-Driven Native Hybrid Queries with Structured and Unstructured Constraints (2022)</strong>  </p>
</li>
<li>
<p><strong>Filtered-DiskANN: Graph Algorithms for Approximate Nearest Neighbor Search with Filters (2023)</strong>  </p>
</li>
<li>
<p><strong>ACORN: Performant and Predicate-Agnostic Search Over Vector Embeddings and Structured Data (2024)</strong>  </p>
</li>
<li>
<p><strong>Navigating Labels and Vectors: A Unified Approach to Filtered Approximate Nearest Neighbor Search (2025)</strong>  </p>
</li>
</ul>
<h3 id="anns_2">流式 ANNS</h3>
<ul>
<li>
<p><strong>AnalyticDB-V: A Hybrid Analytical Engine Towards Query Fusion for Structured and Unstructured Data (2020)</strong>  </p>
</li>
<li>
<p><strong>FreshDiskANN: A Fast and Accurate Graph-Based ANN Index for Streaming Similarity Search (2021)</strong>  </p>
</li>
<li>
<p><strong>In-Place Updates of a Graph Index for Streaming Approximate Nearest Neighbor Search (2025)</strong>  </p>
</li>
</ul>
<hr />
<h2 id="_8">大模型内存管理</h2>
<h3 id="kv-cache">kv cache管理</h3>
<ul>
<li>
<p><strong>Mooncake: A KVCache-centric Disaggregated Architecture for LLM Serving</strong></p>
</li>
<li>
<p><strong>CacheGen: KV Cache Compression and Streaming for Fast Large Language Model Serving</strong></p>
</li>
<li>
<p><strong>CacheBlend: Fast Large Language Model Serving for RAG with Cached Knowledge Fusion</strong></p>
</li>
<li>
<p><strong>KVCache Cache in the Wild: Characterizing and Optimizing KVCache Cache at a Large Cloud Provider</strong></p>
</li>
<li>
<p><strong>SparseServe: Unlocking Parallelism for Dynamic Sparse Attention in Long-Context LLM Serving</strong></p>
</li>
</ul>
<h3 id="_9">训练内存卸载</h3>
<ul>
<li>
<p><strong>vDNN: Virtualized deep neural networks for scalable, memory-efficient neural network design</strong></p>
</li>
<li>
<p><strong>Superneurons: dynamic GPU memory management for training deep neural networks</strong></p>
</li>
<li>
<p><strong>Swapadvisor: Pushing deep learning beyond the gpu memory limit via smart swapping</strong></p>
</li>
<li>
<p><strong>Capuchin: Tensor-based gpu memory management for deep learning</strong></p>
</li>
<li>
<p><strong>Sentinel: Efficient tensor migration and allocation on heterogeneous memory systems for deep learning</strong></p>
</li>
<li>
<p><strong>ZeRO-Offload: Democratizing Billion-Scale Model Training</strong></p>
</li>
<li>
<p><strong>PatrickStar: Parallel Training of Pre-trained Models via Chunk-based Dynamic Memory Management</strong></p>
</li>
</ul>
<h3 id="_10">卸载推理系统</h3>
<ul>
<li>
<p><strong>FlexGen: high-throughput generative inference of large language models with a single GPU (2023)</strong></p>
</li>
<li>
<p><strong>HeteGen: Efficient Heterogeneous Parallel Inference for Large Language Models on Resource-Constrained Devices (2024)</strong></p>
</li>
<li>
<p><strong>NEO: Saving GPU Memory Crisis with CPU Offloading for Online LLM Inference (2024)</strong></p>
</li>
<li>
<p><strong>SpecExec: Massively Parallel Speculative Decoding for Interactive LLM Inference on Consumer Devices (2024)</strong></p>
</li>
<li>
<p><strong>MoE-Lightning: High-Throughput MoE Inference on Memory-constrained GPUs (2024)</strong></p>
</li>
<li>
<p><strong>Klotski: Efficient Mixture-of-Expert Inference via Expert-Aware Multi-Batch Pipeline (2025)</strong></p>
</li>
<li>
<p><strong>FlexInfer: Flexible LLM Inference with CPU Computations (2025)</strong></p>
</li>
</ul>
<hr />
<h2 id="overlap">计算通信 Overlap 优化</h2>
<ul>
<li>
<p><strong>FLUX: Fast Software-based Communication Overlap On GPUs Through Kernel Fusion</strong></p>
</li>
<li>
<p><strong>Comet: Fine-grained Computation-communication Overlapping for Mixture-of-Experts</strong></p>
</li>
<li>
<p><strong>TileLink: Generating Efficient Compute-Communication Overlapping Kernels using Tile-Centric Primitives</strong></p>
</li>
<li>
<p><strong>Triton-distributed: Programming Overlapping Kernels on Distributed AI Systems with the Triton Compiler</strong></p>
</li>
<li>
<p><strong>Efficient and Adaptable Overlapping for Computation and Communication via Signaling and Reordering</strong></p>
</li>
<li>
<p><strong>Characterizing Compute-Communication Overlap in GPU-Accelerated Distributed Deep Learning: Performance and Power Implications</strong></p>
</li>
<li>
<p><strong>FlashDMoE: Fast Distributed MoE in a Single Kernel</strong></p>
</li>
</ul>
<hr />
<h2 id="_11">强化学习</h2>
<ul>
<li>
<p><strong>ReaL: Efficient RLHF Training of Large Language Models with Parameter Reallocation (2025)</strong></p>
</li>
<li>
<p><strong>HybridFlow: A Flexible and Efficient RLHF Framework (2025)</strong></p>
</li>
<li>
<p><strong>Optimizing RLHF Training for Large Language Models with Stage Fusion (2025)</strong></p>
</li>
</ul>
<hr />
<h2 id="for">大模型 for 通信（彭于波）</h2>
<h3 id="_12">语义通信方向</h3>
<ul>
<li>
<p><strong>Large AI model empowered multimodal semantic communications (2024)</strong>  </p>
</li>
<li>
<p><strong>Large language model enhanced multi-agent systems for 6G communications (2024)</strong></p>
</li>
<li>
<p><strong>Large AI model-based semantic communications (2024)</strong>  </p>
</li>
<li>
<p><strong>Large generative model assisted 3D semantic communication (2024)</strong>  </p>
</li>
</ul>
<hr />
<h3 id="_13">多模态通感一体化方向</h3>
<ul>
<li>
<p><strong>Simac: A semantic-driven integrated multimodal sensing and communication framework (2025)</strong></p>
</li>
<li>
<p><strong>Large Language Model Based Multi-Objective Optimization for Integrated Sensing and Communications in UAV Networks (2025)</strong></p>
</li>
<li>
<p><strong>Large Language Models Empower Multimodal Integrated Sensing and Communication (2025)</strong></p>
</li>
<li>
<p><strong>Intelligent Multi-Modal Sensing-Communication Integration: Synesthesia of Machines (2024)</strong></p>
</li>
</ul>
<hr />
<h2 id="_14">投机解码（李世鹏）</h2>
<ul>
<li>
<p><strong>Accelerating Large Language Model Decoding with Speculative Sampling (2023)</strong>  </p>
</li>
<li>
<p><strong>Medusa: Simple LLM Inference Acceleration Framework with Multiple Decoding Heads</strong></p>
</li>
<li>
<p><strong>EAGLE: Speculative Sampling Requires Rethinking Feature Uncertainty</strong> </p>
</li>
<li>
<p><strong>Break the Sequential Dependency of LLM Inference Using Lookahead Decoding</strong></p>
</li>
<li>
<p><strong>Better &amp; Faster Large Language Models via Multi-token Prediction</strong></p>
</li>
<li>
<p><strong>Turning Trash into Treasure: Accelerating Inference of Large Language Models with Token Recycling</strong></p>
</li>
<li>
<p><strong>KOALA: Enhancing Speculative Decoding for LLM via Multi-Layer Draft Heads with Adversarial Learning</strong></p>
</li>
<li>
<p><strong>Accelerated Test-Time Scaling with Model-Free Speculative Sampling</strong></p>
</li>
<li>
<p><strong>Fast Best-of-N Decoding via Speculative Rejection</strong></p>
</li>
</ul>
<hr />
<h2 id="_15">压缩和量化（李世鹏）</h2>
<ul>
<li>
<p><strong>GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers</strong></p>
</li>
<li>
<p><strong>Accurate and Efficient Post-Training Quantization for Large Language Models</strong></p>
</li>
<li>
<p><strong>QServe: W4A8KV4 Quantization and System Co-design for Efficient LLM Serving</strong></p>
</li>
<li>
<p><strong>Matmul or No Matmul in the Era of 1-bit LLMs</strong></p>
</li>
<li>
<p><strong>BitNet a4.8: 4-bit Activations for 1-bit LLMs</strong></p>
</li>
<li>
<p><strong>BitNet v2: Native 4-bit Activations with Hadamard Transformation for 1-bit LLMs</strong></p>
</li>
<li>
<p><strong>GuidedQuant: Large Language Model Quantization via Exploiting End Loss Guidance</strong></p>
</li>
<li>
<p><strong>KVzip: Query-Agnostic KV Cache Compression with Context Reconstruction</strong></p>
</li>
<li>
<p><strong>DynamicKV: Task-Aware Adaptive KV Cache Compression for Long Context LLMs</strong></p>
</li>
<li>
<p><strong>Native Sparse Attention: Hardware-Aligned and Natively Trainable Sparse Attention</strong></p>
</li>
</ul>
<hr />
<h2 id="_16">大模型训练加速（崔正奇）</h2>
<h3 id="_17">在网计算相关</h3>
<ul>
<li>
<p><strong>ATP: In-network Aggregation for Multi-tenant Learning (NSDI 2021)</strong></p>
</li>
<li>
<p><strong>A2TP: Aggregator-aware In-network Aggregation (EuroSys 2023)</strong></p>
</li>
<li>
<p><strong>In-Network Aggregation with Transport Transparency (ASPLOS 2023)</strong></p>
</li>
</ul>
<hr />
<h3 id="_18">分布式训练</h3>
<ul>
<li>
<p><strong>Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism (2019)</strong></p>
</li>
<li>
<p><strong>Pipeline Parallelism Overview</strong></p>
</li>
</ul>
<hr />
<h3 id="_19">拥塞控制</h3>
<ul>
<li>
<p><strong>DCQCN: Data Center Quantized Congestion Notification</strong></p>
</li>
<li>
<p><strong>TIMELY: RTT-based Congestion Control for Datacenter Networks</strong></p>
</li>
</ul>
<hr />
<h2 id="ebpf">网络协议栈优化与eBPF（章振辉）</h2>
<h2 id="tcp">高性能TCP协议栈</h2>
<ul>
<li>
<p><strong>Understanding Host Network Stack Overheads (SIGCOMM 2021)</strong></p>
</li>
<li>
<p><strong>Towards <span class="arithmatex">\(\mu\)</span>s Tail Latency and Terabit Ethernet: Disaggregating the Host Network Stack (SIGCOMM 2022)</strong></p>
</li>
<li>
<p><strong>High-throughput and Flexible Host Networking for Accelerated Computing (OSDI 2024)</strong></p>
</li>
<li>
<p><strong>FlexTOE: Flexible TCP Offload with Fine-Grained Parallelism (NSDI 2022)</strong></p>
</li>
<li>
<p><strong>TAS: TCP Acceleration as an OS Service (EuroSys 2019)</strong></p>
</li>
</ul>
<hr />
<h3 id="ebpf_1">eBPF</h3>
<ul>
<li>
<p><strong>The eXpress data path: fast programmable packet processing in the operating system kernel (ConNEXT 2018)</strong></p>
</li>
<li>
<p><strong>eTran: Extensible Kernel Transport with eBPF (NSDI 2025)</strong></p>
</li>
<li>
<p><strong>FetchBPF: Customizable Prefetching Policies in Linux with eBPF (ATC 2024)</strong></p>
</li>
<li>
<p><strong>NetEdit: An Orchestration Platform for eBPF Network Functions at Scale (SIGCOMM 2024)</strong></p>
</li>
</ul>
<hr />
<h2 id="related-papers-in-sosp25">Related Papers in SOSP25</h2>
<h3 id="llm-training">LLM Training</h3>
<ul>
<li>
<p><strong>Robust LLM Training Infrastructure at ByteDance (SOSP2025)</strong></p>
</li>
<li>
<p><strong>Sailor: Automating Distributed Training over Dynamic, Heterogeneous, and Geo-distributed Clusters (SOSP2025)</strong></p>
</li>
<li>
<p><strong>DCP: Addressing Input Dynamism In Long-Context Training via Dynamic Context Parallelism (SOSP2025)</strong></p>
</li>
<li>
<p><strong>TrainVerify: Equivalence-Based Verification for Distributed LLM Training (SOSP2025)</strong></p>
</li>
<li>
<p><strong>Mycroft: Tracing Dependencies in Collective Communication Towards Reliable LLM Training (SOSP2025)</strong></p>
</li>
</ul>
<h3 id="llm-inference">LLM Inference</h3>
<ul>
<li>
<p><strong>Characterizing Mobile SoC for Accelerating Heterogeneous LLM Inference (SOSP2025)</strong></p>
</li>
<li>
<p><strong>IC-Cache: Efficient Large Language Model Serving via In-context Caching (SOSP2025)</strong></p>
</li>
<li>
<p><strong>PrefillOnly: An Inference Engine for Prefill-only Workloads in Large Language Model Applications (SOSP2025)</strong></p>
</li>
<li>
<p><strong>Pie: A Programmable Serving System for Emerging LLM Applications (SOSP2025)</strong></p>
</li>
<li>
<p><strong>DiffKV: Differentiated Memory Management for Large Language Models with Parallel KV Compaction (SOSP2025)</strong></p>
</li>
<li>
<p><strong>Jenga: Effective Memory Management for Serving LLM with Heterogeneity  (SOSP2025)</strong></p>
</li>
</ul>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "..", "features": [], "search": "../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../assets/javascripts/bundle.f55a23d4.min.js"></script>
      
        <script src="../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>